{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6abb104-0cf7-47c2-8648-9ab2d5b37569",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#1a73e8;\">2.3.6 Feature Selection: Beyond Naive Approaches</h4>\n",
    "\n",
    "While encoding prepares features for modeling, **feature selection** reduces dimensionality, improves interpretability, and mitigates overfitting. We now expand on the initial coverage with deeper context.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Feature Selection Matters**\n",
    "\n",
    "- **Curse of Dimensionality**: More features → sparser data → higher variance.\n",
    "- **Computational Efficiency**: Fewer features → faster training.\n",
    "- **Model Interpretability**: Simpler models are easier to explain.\n",
    "- **Noise Reduction**: Irrelevant features add variance without signal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Three Paradigms of Feature Selection**\n",
    "\n",
    "1. **Filter Methods**:  \n",
    "   Use statistical metrics **independent of any model**. Fast and scalable.\n",
    "   - **Chi-Square Test**: For **categorical input vs. categorical target** (classification).\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48bd4f-788d-4ab6-a1d5-85827bacd7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "selector = SelectKBest(score_func=chi2, k=5)\n",
    "X_selected = selector.fit_transform(X_train_cat, y_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2845a1-ae9c-4f0f-8973-2b558237764c",
   "metadata": {},
   "source": [
    "- **ANOVA F-test**: For **numerical input vs. categorical target**.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4134e9-510a-4feb-84ef-1bda99271324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "selector = SelectKBest(score_func=f_classif, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b36dc6-7b36-44c7-97be-a92923463891",
   "metadata": {},
   "source": [
    "- **Mutual Information**: Model-agnostic; works for **any input/target type**.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78339cac-f57c-4fc0-bf8c-71639dd566b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "# For classification:\n",
    "mi_scores = mutual_info_classif(X_train, y_train)\n",
    "# For regression:\n",
    "mi_scores = mutual_info_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bd3e1-d11b-423a-9c20-39f34284a78e",
   "metadata": {},
   "source": [
    "2. **Wrapper Methods**:  \n",
    "   Use a **specific model** to evaluate feature subsets. More accurate but computationally heavy.\n",
    "   - **Recursive Feature Elimination (RFE)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c806635-0b55-4707-a1af-8dbb1124ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "estimator = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "rfe = RFE(estimator, n_features_to_select=8, step=1)\n",
    "X_rfe = rfe.fit_transform(X_train, y_train)\n",
    "selected = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a419c-419f-4c1c-bbbb-aa289de7e35e",
   "metadata": {},
   "source": [
    "- **Forward/Backward Selection**: Not natively in sklearn; use `mlxtend`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42cd4e-d132-40e4-8a9e-705db7384f3d",
   "metadata": {},
   "source": [
    "3. **Embedded Methods**:  \n",
    "   Feature selection **built into the model training**.\n",
    "   - **Lasso (L1 regularization)**: Shrinks irrelevant feature weights to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cff207-d983-4b2d-981d-e588c9e72b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(cv=5).fit(X_train_scaled, y_train)\n",
    "selected = X_train.columns[lasso.coef_ != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce631053-d4e6-4963-89d1-571cf733daad",
   "metadata": {},
   "source": [
    "- **Tree-based importance**: From Random Forest or XGBoost.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fd4ae-df04-4f11-8409-78db894534af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "top_features = importances.nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d4a02-2346-4be9-9706-6e5510f6cef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f98fa-1588-4f79-ad25-df11c9318c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
